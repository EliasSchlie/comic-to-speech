import os
import sys
import torch
import types
import warnings

# â”€â”€â”€ Silence noisy warnings â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=FutureWarning)

# â”€â”€â”€ Minimal mock for pyonmttok to avoid binary dependency issues â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _fake_build_vocab_from_tokens(vocab_dict):
    """Mock replacement for OpenNMT-py vocab building."""
    return vocab_dict

sys.modules["pyonmttok"] = types.SimpleNamespace(
    Tokenizer=lambda *a, **kw: None,
    build_tokenizer=lambda *a, **kw: None,
    build_vocab_from_tokens=_fake_build_vocab_from_tokens
)

# â”€â”€â”€ Lazy import of OpenNMT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def lazy_import_onmt():
    global build_translator, OnmtArgParser
    from onmt.translate.translator import build_translator
    from onmt.utils.parse import ArgumentParser as OnmtArgParser


# â”€â”€â”€ Paths â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE_DIR = os.path.abspath(os.path.dirname(__file__))
MODEL_PATH = os.path.join(BASE_DIR, "model_step_22000.pt")
BPE_MODEL_PATH = os.path.join(BASE_DIR, "bpe.model")


# â”€â”€â”€ Translation Function â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def translate_text(texts, src_lang="en", tgt_lang="bg"):
    """
    Translate a list of sentences using the fine-tuned OpenNMT model.
    """
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"Model checkpoint not found: {MODEL_PATH}")
    if not os.path.exists(BPE_MODEL_PATH):
        raise FileNotFoundError(f"BPE model not found: {BPE_MODEL_PATH}")

    lazy_import_onmt()

    # Create temp input/output files
    src_file = os.path.join(BASE_DIR, "_temp_input.txt")
    out_file = os.path.join(BASE_DIR, "_temp_output.txt")

    with open(src_file, "w", encoding="utf-8") as f:
        for line in texts:
            f.write(line.strip() + "\n")

    parser = OnmtArgParser()
    opt = parser.parse_known_args(args=[
        "-model", MODEL_PATH,
        "-src", src_file,
        "-output", out_file,
        "-replace_unk",
        "-verbose"
    ])[0]

    # â”€â”€â”€ Compatibility fixes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    setattr(opt, "output", out_file)
    setattr(opt, "models", [MODEL_PATH])
    setattr(opt, "gpu", -1)  # CPU mode

    # â”€â”€â”€ Fix for PyTorch 2.6+ (safe unpickling) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    import torch.serialization, argparse
    torch.serialization.add_safe_globals([argparse.Namespace])

    # â”€â”€â”€ Auto-fix for old checkpoint vocab format â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    checkpoint = torch.load(MODEL_PATH, map_location="cpu", weights_only=False)
    if isinstance(checkpoint.get("vocab"), list):
        checkpoint["vocab"] = {"src": checkpoint["vocab"][0], "tgt": checkpoint["vocab"][1]}
        torch.save(checkpoint, MODEL_PATH)
        print("ðŸ§© Patched vocabulary format in checkpoint.")

    # â”€â”€â”€ Build and run translator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    translator = build_translator(opt, report_score=False)
    translator.translate(
        src_path=src_file,
        tgt_path=None,
        src_dir="",
        batch_size=32
    )

    # â”€â”€â”€ Read output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with open(out_file, "r", encoding="utf-8") as f:
        result = [line.strip() for line in f.readlines()]

    # â”€â”€â”€ Cleanup temp files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    os.remove(src_file)
    os.remove(out_file)

    return result


# â”€â”€â”€ Manual test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    test_sentences = ["This is working!", "I love AI.", "How are you?"]
    translations = translate_text(test_sentences)

    print("\nâœ… Translation results:")
    print("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    for src, tgt in zip(test_sentences, translations):
        print(f"{src} â†’ {tgt}")
